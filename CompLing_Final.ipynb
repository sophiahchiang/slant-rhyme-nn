{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sophiahchiang/slant-rhyme-nn/blob/main/CompLing_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjQLm9kqU9-V",
        "outputId": "cd744f38-3f35-4673-bc33-37dcfa0b2cc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pronouncing in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: cmudict>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from pronouncing) (1.0.2)\n",
            "Requirement already satisfied: eng-to-ipa in /usr/local/lib/python3.7/dist-packages (0.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Packages\n",
        "!pip install pronouncing\n",
        "!pip install eng-to-ipa\n",
        "import pronouncing as pro\n",
        "import eng_to_ipa as ipa\n",
        "import numpy as np\n",
        "import re\n",
        "import math\n",
        "import string\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import io\n",
        "import pandas as pd\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPgkPUJ76Lnp"
      },
      "outputs": [],
      "source": [
        "# Small test corpus (Sean)\n",
        "corpus = '''\n",
        "         IN A SHORT speech on November 19th Narendra Modi, India’s prime minister, made a humiliating U-turn. Barely a year after rushing a trio of laws reforming agriculture through parliament, he announced their repeal. The shame was not only to have handed victory to the horde of tractor-mounted yokels doggedly protesting at the gates of India’s capital since last November. It was to have bungled the issue from the start. Indian farming does indeed desperately need reform. Yet Mr Modi made no effort to build consensus for his three new laws last year, instead ramming them through parliament without debate. When north Indian farmers, many of whom happen to be Sikh, protested, he doubled their fury by tagging them thugs and traitors. The most powerful Indian leader in a generation then did nothing for months, as if the stand-off were someone else’s problem. That is, not until elections in a couple of important farm states drew uncomfortably near, whereupon Mr Modi crumpled completely. In another democracy a leader who flouted parliament, broke trust with an influential religious minority and insisted on and then scrapped controversial reforms would pay a heavy political price. But although the farm-bill fiasco is only the latest link in a long and heavy chain of embarrassments under Mr Modi, the white-bearded prime minister remains largely unscathed. Admirers ascribe his staying power to personal charisma. They say he projects the strength and dignity Indian voters crave in their own lives. Detractors point instead to the deep pockets, ruthlessness and military discipline of his Bharatiya Janata Party (BJP), quietly buttressed by a web of allied Hindu-nationalist organisations and noisily amplified by relentless propaganda. All this surely counts, yet would not suffice without another secret weapon: the opposition. Throughout Mr Modi’s term and a half in power, the BJP’s opponents have remained divided, weak and largely ineffectual. This does not mean they have given the prime minister a free ride. Such misguided policies as “demonetisation”, the withdrawal from circulation in 2016 of high-denomination notes in a delusional bid to chase out “black money”, or the BJP’s gleeful stoking of Islamophobia in a country with 200m Muslims, or Mr Modi’s erratic handling of covid-19, including fierce lockdowns that wrecked small businesses and stranded millions of migrant workers, followed by complacent laxity as India’s second wave became a murderous tsunami—all this has made it easy for opposition politicians to fire up disgruntled constituents. But despite landing the odd blow against Mr Modi, and beating the BJP in the occasional state election, they have so far failed to shift India’s broader narrative. In opposition in the years before 2014, the BJP had by contrast skilfully and relentlessly undermined the sitting government, plucking at every speck of possible evidence to build a damning—and in retrospect largely unfair—picture of weakness and venality.\n",
        "         '''\n",
        "corpus = corpus.lower().strip()\n",
        "corpus = re.sub('[%s]' % re.escape(string.punctuation), '', corpus)\n",
        "# Gets only unique words from corpus (we don't have to do this but it reduces computation later)\n",
        "corpus = set(corpus.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwZ_n88C8mc0"
      },
      "outputs": [],
      "source": [
        "# Find rhymes for every word in corpus by building rhyme dictionary\n",
        "def build_rhyme_dictionary(corpus):\n",
        "    '''\n",
        "    Builds a dictionary of rhymes from the word corpus\n",
        "\n",
        "    Input (set): Word corpus\n",
        "\n",
        "    Output (dict): Rhyming dictionary\n",
        "    '''\n",
        "    rhyme_d = dict()\n",
        "    for word in corpus:\n",
        "        rhymes = pro.rhymes(word)\n",
        "        if not rhymes:\n",
        "            continue\n",
        "        for rhyme in rhymes:\n",
        "            if rhyme in corpus:\n",
        "                if word in rhyme_d:\n",
        "                    rhyme_d[word].add(rhyme)\n",
        "                else:\n",
        "                    rhyme_d[word] = {rhyme}\n",
        "    return rhyme_d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiGqcTp1E7ab"
      },
      "outputs": [],
      "source": [
        "# Create list of input tuples form rhyme dictionary\n",
        "# This method doesn't remove duplicates so ('to', 'drew') and ('drew', 'to')\n",
        "# are both included in final list (this can be changed)\n",
        "def get_rhyme_pairs(rhyme_d):\n",
        "    '''\n",
        "    Creates a set of rhyme pairs from rhyme dictionary\n",
        "\n",
        "    Input (dict): rhyme dictionary\n",
        "\n",
        "    Output (list): list of rhyme pairs\n",
        "    '''\n",
        "    rhyme_pairs = list()\n",
        "    for k, v in rhyme_d.items():\n",
        "        for word in v:\n",
        "            if (word, k) in rhyme_pairs:\n",
        "                continue\n",
        "            pair = (k, word)\n",
        "            rhyme_pairs.append(pair)\n",
        "    return rhyme_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-mzplLE5az4"
      },
      "outputs": [],
      "source": [
        "def get_non_rhyme_pairs(rhyme_pairs, corpus):\n",
        "    '''\n",
        "    Generates a list of non-rhyming word pairs from corpus with pseudo-randomness\n",
        "\n",
        "    Inputs:\n",
        "      rhyme_pairs (list): list of rhyming words (tuples)\n",
        "      corpus (list): list of strings\n",
        "\n",
        "    Output:\n",
        "      non_rhyme_pairs (list): list of non-rhyming words (tuples)\n",
        "    '''\n",
        "    non_rhyme_pairs = set()\n",
        "    while len(non_rhyme_pairs) < len(rhyme_pairs):\n",
        "        random_index_1, random_index_2 = random.randint(0, len(corpus)-1), random.randint(0, len(corpus)-1)\n",
        "        if random_index_1 == random_index_2:\n",
        "            continue\n",
        "        random_bi = random.randint(0, 1)\n",
        "        potential_word_1, potential_word_2 = corpus[random_index_1][random_bi], corpus[random_index_2][random_bi]\n",
        "        # make sure potential words don't rhyme\n",
        "        if potential_word_1 in pro.rhymes(potential_word_2):\n",
        "            continue\n",
        "        non_rhyme_pairs.add((potential_word_1, potential_word_2))\n",
        "    non_rhyme_pairs = list(non_rhyme_pairs)\n",
        "    return non_rhyme_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dNrCFdxwVqw"
      },
      "outputs": [],
      "source": [
        "# New Function That Uses a Hard-Coded List of IPA Characters and converts\n",
        "# the word pairs into their numerical representation\n",
        "\n",
        "# Defining the IPA Chars List\n",
        "ipa_alphabet = ['i', 'ɪ', 'y', 'e', 'ə', 'ʊ', 'u', 'o', 'ɛ', 'æ', 'a', 'ɑ', 'ɔ',\n",
        "                'p', 'b', 'm', 'f', 'v', 'θ', 'ð', 's', 't', 'z', 'r', 'd', 'n',\n",
        "                'ʃ', 'ʒ', 'l', 'x', 'k', 'ŋ', 'c', 'g', 'q', 'w', 'j', 'h', 'ʤ', 'ʧ']\n",
        "num_chars = len(ipa_alphabet)\n",
        "\n",
        "'''\n",
        "A Brief Note on How We Are Doing Numerical Representations:\n",
        "The above alphabet list orders the various phones by their closeness in sound.\n",
        "When we convert the phonetic representation of words into a numerical one, we are\n",
        "simply finding the index (we will call 'idx') of that phone in the list, and then\n",
        "adding one and dividing by the total number of phones:\n",
        "\n",
        "    Numerical Representation of Phone = (idx+1)/length(ipa_alphabet)\n",
        "\n",
        "'''\n",
        "\n",
        "def convert_to_numerical(word_pairs):\n",
        "  '''\n",
        "  Steps through word pairs (rhyme_pairs or non_rhyme_pairs) and\n",
        "  converts each word first into its phonetic representation, and then\n",
        "  uses the 'ipa_alphabet' list to convert the phonetic representation\n",
        "  into a numerical one. Returns the pairs in numerical form.\n",
        "\n",
        "  Input (list): list of word pairs (english representation)\n",
        "\n",
        "  Output (list): list of word pairs (numerical representation)\n",
        "  '''\n",
        "\n",
        "  numerical_pairs = list() # new list to be returned\n",
        "  for index, tuple in enumerate(word_pairs):\n",
        "    if index % 100 == 0:\n",
        "      print(index)\n",
        "\n",
        "    # Convert words to phonetic representations\n",
        "    word1 = ipa.convert(tuple[0])\n",
        "    word2 = ipa.convert(tuple[1])\n",
        "\n",
        "    # Remove all ˈ or ˌ from the words as these are not very relevant\n",
        "    word1 = word1.replace(\"ˈ\", \"\")\n",
        "    word1 = word1.replace(\"ˌ\", \"\")\n",
        "    word1 = word1.replace(\"*\", \"\")\n",
        "    word2 = word2.replace(\"ˈ\", \"\")\n",
        "    word2 = word2.replace(\"ˌ\", \"\")\n",
        "    word2 = word2.replace(\"*\", \"\")\n",
        "\n",
        "    # For each word, step through and get numerical rep\n",
        "    word1_num = []\n",
        "    word2_num = []\n",
        "    for j in range(len(word1)):\n",
        "      idx = ipa_alphabet.index(word1[j])\n",
        "      word1_num.append((idx+1)/num_chars)\n",
        "\n",
        "    for j in range(len(word2)):\n",
        "      idx = ipa_alphabet.index(word2[j])\n",
        "      word2_num.append((idx+1)/num_chars)\n",
        "\n",
        "    # Append numerical pair to the 'numerical_pairs' list\n",
        "    num_tuple = (word1_num, word2_num)\n",
        "    numerical_pairs.append(num_tuple)\n",
        "\n",
        "  # return new list\n",
        "  return numerical_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ii5kJDKQx_g_"
      },
      "outputs": [],
      "source": [
        "# TESTING NEW FUNCTION\n",
        "\n",
        "def convert_to_tensor(word_pairs):\n",
        "\n",
        "  input = np.zeros((len(word_pairs), num_chars*2))\n",
        "\n",
        "  null_indices = [] # indices to remove later (for try/catch block)\n",
        "\n",
        "  for index, tuple in enumerate(word_pairs):\n",
        "    if index % 100 == 0:\n",
        "      print(index)\n",
        "\n",
        "    # Convert words to phonetic representations\n",
        "    try:\n",
        "      word1 = ipa.convert(tuple[0])\n",
        "      word2 = ipa.convert(tuple[1])\n",
        "    except:\n",
        "      print(\"NaN Line Created\")\n",
        "      null_indices.append(index)\n",
        "      continue\n",
        "    # Remove all ˈ or ˌ from the words as these are not very relevant\n",
        "    word1 = word1.replace(\"ˈ\", \"\")\n",
        "    word1 = word1.replace(\"ˌ\", \"\")\n",
        "    word1 = word1.replace(\"*\", \"\")\n",
        "    word2 = word2.replace(\"ˈ\", \"\")\n",
        "    word2 = word2.replace(\"ˌ\", \"\")\n",
        "    word2 = word2.replace(\"*\", \"\")\n",
        "\n",
        "    # Only take last 6 characters\n",
        "    word1 = word1[-6:]\n",
        "    word2 = word2[-6:]\n",
        "    lw1 = len(word1)\n",
        "    lw2 = len(word2)\n",
        "\n",
        "    word1_nums = [0] * num_chars\n",
        "    word2_nums = [0] * num_chars\n",
        "    for j in range(lw1):\n",
        "      idx = ipa_alphabet.index(word1[j])\n",
        "      if lw1 > 1:\n",
        "        word1_nums[idx] = float(j+1) / lw1\n",
        "      else:\n",
        "        word1_nums[idx] = float(j+1)\n",
        "    for g in range(lw2):\n",
        "      idx = ipa_alphabet.index(word2[g])\n",
        "      if lw2 > 1:\n",
        "        word2_nums[idx] = float(g+1) / lw2\n",
        "      else:\n",
        "        word2_nums[idx] = float(g+1)\n",
        "\n",
        "    input[index][:] = np.concatenate((np.array(word1_nums), np.array(word2_nums)))\n",
        "\n",
        "  # return new list (remove NaN rows)\n",
        "  input = np.delete(input, null_indices, axis=0)\n",
        "  return input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L37Dct6DlRYU"
      },
      "outputs": [],
      "source": [
        "# Final step in shaping the input:\n",
        "# We want the input to be of the form of a 2D array, in which each row is a\n",
        "# 12 unit long numerical array, and the number of rows is then the number of possible inputs\n",
        "# we have to train and test the model (aka the number of word rhyme pairs).\n",
        "# Let's have the array be 12 units in length (meaning we will have 12 input nodes)\n",
        "# The first six indices are for the first word, the second six are for the second word.\n",
        "# If the word is six phones long, then it fits perfectly.\n",
        "# If the word is >6 phones long, then we will truncate it -- cut off the beggining of the word.\n",
        "# If the word is <6 phones long, we will pad the beginning with zeros.\n",
        "\n",
        "def transform_to_input(num_pairs):\n",
        "  input = np.zeros((len(num_pairs), 12))\n",
        "\n",
        "  for index, tuple in enumerate(num_pairs):\n",
        "    # Getting words\n",
        "    word1 = tuple[0]\n",
        "    word2 = tuple[1]\n",
        "\n",
        "    # Getting lengths of word arrays\n",
        "    word1_len = len(word1)\n",
        "    word2_len = len(word2)\n",
        "\n",
        "    # Getting 6-long array for word1\n",
        "    if (word1_len >= 6):\n",
        "      word1_input = np.array(word1[-6:])\n",
        "    else:\n",
        "      word1_input = np.concatenate((np.zeros(6-word1_len), np.array(word1)))\n",
        "\n",
        "    # Same for word2\n",
        "    if (word2_len >= 6):\n",
        "      word2_input = np.array(word2[-6:])\n",
        "    else:\n",
        "      word2_input = np.concatenate((np.zeros(6-word2_len), np.array(word2)))\n",
        "\n",
        "    input[index][:] = np.concatenate((word1_input, word2_input))\n",
        "\n",
        "  return input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "U7sRwF0VqXfk",
        "outputId": "97a03021-e649-4e92-ca2a-7d5ffed94f0e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-136797d5-3407-4266-9a77-b7ccd8371182\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-136797d5-3407-4266-9a77-b7ccd8371182\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfvwWCEg6hdi"
      },
      "outputs": [],
      "source": [
        "# Using above functions, get rhyming and non-rhyming pairs from corpus and then\n",
        "# format an input (X) tensor array and a desired output (Y) tensor array\n",
        "\n",
        "# Build the rhyme dictionary\n",
        "#rhyme_d = build_rhyme_dictionary(corpus)\n",
        "\n",
        "# Oranize that all into rhyming pairs and non-rhyming pairs\n",
        "#rhyme_pairs = get_rhyme_pairs(rhyme_d)\n",
        "#non_rhyme_pairs = get_non_rhyme_pairs(rhyme_pairs)\n",
        "\n",
        "# First, use the CSV files to get the rhyming pairs and non-rhyming pairs\n",
        "rhyme_df = pd.read_csv(io.BytesIO(uploaded['rhyme_pairs_strict.csv']))\n",
        "non_rhyme_df = pd.read_csv(io.BytesIO(uploaded['non_rhyme_pairs_strict.csv']))\n",
        "\n",
        "rhyme_rec = rhyme_df.to_records(index=False)\n",
        "non_rhyme_rec = non_rhyme_df.to_records(index=False)\n",
        "rhyme_pairs = list(rhyme_rec)\n",
        "non_rhyme_pairs = list(non_rhyme_rec)\n",
        "\n",
        "# Limiting the Size\n",
        "# size = 10000\n",
        "# rhyme_pairs_numerical = convert_to_tensor(rhyme_pairs[0:size])\n",
        "# non_rhyme_pairs_numerical = convert_to_tensor(non_rhyme_pairs[0:size])\n",
        "\n",
        "# Entire Datasets\n",
        "rhyme_pairs_numerical = convert_to_tensor(rhyme_pairs)\n",
        "non_rhyme_pairs_numerical = convert_to_tensor(non_rhyme_pairs)\n",
        "\n",
        "\n",
        "# Convert the above lists into their numerical representations\n",
        "#rhyme_pairs_numerical = convert_to_numerical(rhyme_pairs[0:1000])\n",
        "#non_rhyme_pairs_numerical = convert_to_numerical(non_rhyme_pairs[0:1000])\n",
        "\n",
        "# Now, I want to create a combined list, and another list that tracks\n",
        "# whether the pair at each index is a rhyme or non_rhyme: this will be\n",
        "# a binary list with 1 for rhyme pair and 0 for non_rhyme pair.\n",
        "all_word_pairs = np.concatenate((rhyme_pairs_numerical, non_rhyme_pairs_numerical))\n",
        "rhyme_binary = ([1] * len(rhyme_pairs_numerical)) + ([0] * len(non_rhyme_pairs_numerical))\n",
        "\n",
        "# Now, I want to zip() the lists and then shuffle() and then unzip()\n",
        "temp = list(zip(all_word_pairs, rhyme_binary))\n",
        "random.shuffle(temp)\n",
        "all_word_pairs, rhyme_binary = zip(*temp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCQjuqNtsiZF"
      },
      "outputs": [],
      "source": [
        "# Transform the binary list into desired 2-node output format\n",
        "\n",
        "b = list(rhyme_binary)\n",
        "b = map(lambda n: (n, 0) if n == 1.0 else (0, 1), b)\n",
        "rhyme_binary_tup = list(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiLW7whnogZp"
      },
      "outputs": [],
      "source": [
        "# Inputs\n",
        "#X = transform_to_input(all_word_pairs)\n",
        "X = np.array(all_word_pairs)\n",
        "\n",
        "# True Y values\n",
        "#Y = np.expand_dims(np.array(rhyme_binary), axis=1)\n",
        "Y = np.array(rhyme_binary_tup)\n",
        "\n",
        "print(\"Input and Output Tensor Shapes\")\n",
        "print(\"Input: \", X.shape)\n",
        "print(\"Output: \", Y.shape)\n",
        "\n",
        "# Make X,Y tensors\n",
        "X = torch.tensor(X)\n",
        "#X = torch.nn.functional.normalize(X, p=2.0, dim=1, eps=1e-12, out=None)\n",
        "Y = torch.tensor(Y).float()\n",
        "#Y = torch.tensor(Y)\n",
        "\n",
        "print(\"\\nINSPECTION\")\n",
        "idxx = 2\n",
        "print(X[idxx][0:40])\n",
        "print(X[idxx][40:])\n",
        "print(Y[idxx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPUyBNIIx1na"
      },
      "outputs": [],
      "source": [
        "# Trying to understand DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "dataset = TensorDataset(X, Y)\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "# transform = transforms.Compose([transforms.ToTensor(),\n",
        "#                               transforms.Normalize((0.5,), (0.5,)),])\n",
        "\n",
        "# Download and load the training data\n",
        "# dataset = transform(dataset)\n",
        "\n",
        "# Determining train_test split\n",
        "total_pairs = X.shape[0]\n",
        "train_div = int(math.floor(total_pairs*.8))\n",
        "test_div = int(math.ceil(total_pairs*.2))\n",
        "\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [train_div, test_div])\n",
        "trainloader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(val_set, batch_size=test_div, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGWoPI9mjy7x"
      },
      "outputs": [],
      "source": [
        "# Create Neural Network Using Torch Sequential\n",
        "\n",
        "input_dim = 80 # 12 input nodes\n",
        "hidden_dim = 120 # 120 hidden layer nodes\n",
        "output_dim = 2 # 2 output nodes\n",
        "\n",
        "# Define Model Quickly\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(input_dim, hidden_dim),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(hidden_dim, output_dim),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "\n",
        "# Define the loss\n",
        "#criterion = nn.NLLLoss()\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 1000\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for inputs, labels in trainloader:\n",
        "    # Training pass\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(inputs.float())\n",
        "    loss = criterion(output, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir-Hl3eyYInU"
      },
      "outputs": [],
      "source": [
        "# Test\n",
        "for inputs, labels in testloader:\n",
        "    output = model(inputs.float())\n",
        "    #print(output.shape)\n",
        "    output = (output>0.5).float()\n",
        "    #print(output.shape)\n",
        "    #print(output[1])\n",
        "    #print(labels[1])\n",
        "    #print(labels.shape)\n",
        "    correct = (output == labels).sum() / 2\n",
        "    print(\"Accuracy = \", correct / inputs.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3FfSgLcUveQ"
      },
      "outputs": [],
      "source": [
        "#Function that takes in pairs of words and outputs 3D array\n",
        "#each word represented by matrix where every column is 1 phone\n",
        "\n",
        "# TESTING NEW FUNCTION\n",
        "\n",
        "def convert_to_tensor2(word_pairs):\n",
        "\n",
        "  input = np.zeros((len(word_pairs), 6, num_chars*2))\n",
        "\n",
        "  null_indices = [] # indices to remove later (for try/catch block)\n",
        "\n",
        "  for index, tuple in enumerate(word_pairs):\n",
        "    if index % 100 == 0:\n",
        "      print(index)\n",
        "\n",
        "    # Convert words to phonetic representations\n",
        "    try:\n",
        "      word1 = ipa.convert(tuple[0])\n",
        "      word2 = ipa.convert(tuple[1])\n",
        "    except:\n",
        "      print(\"IPA Conversion Failed, Removing Word Pair...\")\n",
        "      null_indices.append(index)\n",
        "      continue\n",
        "\n",
        "    # Remove all ˈ or ˌ from the words as these are not very relevant\n",
        "    word1 = word1.replace(\"ˈ\", \"\")\n",
        "    word1 = word1.replace(\"ˌ\", \"\")\n",
        "    word1 = word1.replace(\"*\", \"\")\n",
        "    word2 = word2.replace(\"ˈ\", \"\")\n",
        "    word2 = word2.replace(\"ˌ\", \"\")\n",
        "    word2 = word2.replace(\"*\", \"\")\n",
        "\n",
        "    # Only take last 6 characters\n",
        "    word1 = word1[-6:]\n",
        "    word2 = word2[-6:]\n",
        "    lw1 = len(word1)\n",
        "    lw2 = len(word2)\n",
        "\n",
        "    word1_nums = np.zeros((num_chars,6))\n",
        "    word2_nums = np.zeros((num_chars,6))\n",
        "\n",
        "    #makes each tuple into array w/ 1 at designated phone index\n",
        "    for j in range(lw1):\n",
        "      idx = ipa_alphabet.index(word1[j])\n",
        "      word1_nums[idx,j] = 1\n",
        "    for g in range(lw2):\n",
        "      idx = ipa_alphabet.index(word2[g])\n",
        "      word2_nums[idx,g] = 1\n",
        "\n",
        "    input[index][:][:] = np.concatenate((np.array(word1_nums), np.array(word2_nums)), axis=0)\n",
        "    print(input[index][:][:].shape)\n",
        "\n",
        "  # return new list (remove NaN rows)\n",
        "  input = np.delete(input, null_indices, axis=0)\n",
        "  return input\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2TYDTXsc4vd"
      },
      "outputs": [],
      "source": [
        "#Create Recurrent Neural Network\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, hidden_dim, n_layers):\n",
        "    super(Model, self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_layers = n_layers\n",
        "\n",
        "    self.rnn = nn.RNN(input_dim, hidden_dim, n_layers, batch_first = True)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    batch_size = x.size(0)\n",
        "    hidden = self.init_hidden(batch_size)\n",
        "    out, hidden = self.rnn(x, hidden)\n",
        "    out = out.contiguous().view(-1, self.hidden_dim)\n",
        "    out = self.fc(out)\n",
        "\n",
        "    return out, hidden\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    hidden = torch.zeros(self.n_layers,batch_size,self.hidden_dim)\n",
        "    return hidden\n",
        "\n",
        "#Define parameters and model\n",
        "\n",
        "input_dim = 12 # 12 input nodes\n",
        "hidden_dim = 100 # 100 hidden layer nodes\n",
        "output_dim = 2\n",
        "n_layers = 1\n",
        "n_epochs = 100\n",
        "\n",
        "rnn_model = Model(input_dim, output_dim,hidden_dim,n_layers)\n",
        "\n",
        "#Define Loss and Adam optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(rnn_model.parameters(),lr=0.004)\n",
        "\n",
        "batch = 100\n",
        "seq = 6\n",
        "encoding size = 80\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
